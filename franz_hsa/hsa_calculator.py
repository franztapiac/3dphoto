from pathlib import Path
from tools.DataSetGraph import ReadPolyData, WritePolyData
from Analyze3DPhotogram import PlaceLandmarks, ComputeHSAandRiskScore
from vtkmodules.util import numpy_support
import re
import pandas as pd
import os
import pyvista as pv
import datetime
import json
import random
random.seed(0)


def get_landmark_coordinates(landmarks_vtp):
    """Extract the landmark coordinates from a vtkPolyData object.

    Args:
        landmarks_vtp (vtkPolyData): The VTK PolyData object containing the landmarks.

    Returns:
        ndarray: A NumPy array with shape (n, 3) where each row contains the (x, y, z) coordinates of a landmark.
    """
    points = landmarks_vtp.GetPoints()
    dataArray = points.GetData()
    landmark_coordinates = numpy_support.vtk_to_numpy(dataArray)
    return landmark_coordinates


def load_hsa_scores(file_path):

    probability_data = pd.read_excel(file_path, header=None)

    header = probability_data.iloc[0]
    subtypes_df = header[header.notna()]
    subtypes = subtypes_df.values.tolist()
    subtypes_cols = subtypes_df.index.tolist()

    hsa_scores = dict()

    for i, subtype in enumerate(subtypes):
        hsa_scores[subtype] = dict()
        mesh_ids = probability_data.iloc[2:, subtypes_cols[i]]
        mesh_ids = mesh_ids[mesh_ids.notna()].tolist()
        subtype_data = probability_data.iloc[2:, subtypes_cols[i]+1]
        subtype_data = subtype_data[subtype_data.notna()].tolist()
        subtype_data = [float(item) for item in subtype_data]
        for j, mesh_id in enumerate(mesh_ids):
            hsa_scores[subtype][mesh_id] = subtype_data[j]
    return hsa_scores


def export_to_excel(data_dict, output_path):

    with pd.ExcelWriter(str(output_path.absolute())) as writer:
        for i, subtype in enumerate(list(data_dict.keys())):
            print(f'Exporting {subtype}...')

            # Generating the dataframe from the dictionary
            size = len(data_dict.keys())
            df = pd.DataFrame.from_dict(data_dict[subtype], orient='index', columns=['HSA index'])
            df.to_excel(writer, sheet_name='Sheet1', startcol=i*(size+2), startrow=1, index=True)


def get_mesh_info(mesh_vtp_file_path):

    pattern = r'^(.*?)_inst_(\d{3})_cp$'
    match = re.match(pattern, mesh_vtp_file_path.stem)
    mesh_subtype = match.group(1)
    mesh_id_num = int(match.group(2))

    return mesh_subtype, mesh_id_num


def export_landmarks_object(landmarks, mesh_file_path):
    """
    Exports the generated landmarks object in three formats: .ply, .vtk, and .vtp
    :param landmarks: a vtk object for the landmarks object generated by the published method
    :param mesh_file_path: a Path object for the file path to the considered mesh
    """
    extensions = ['.ply', '.vtp', '.vtk']
    for extension in extensions:
        landmarks_file_path = mesh_file_path.parent / 'predicted_landmarks_object' / (mesh_file_path.stem +
                                                                                      '_predicted_landmarks' +
                                                                                      extension)
        if not os.path.exists(landmarks_file_path.parent):
            os.makedirs(landmarks_file_path.parent)
        WritePolyData(landmarks, str(landmarks_file_path.absolute()))


def export_ply_landmark_coordinates(landmark_coordinates, vtp_mesh_file_path, time_now):
    """
    Export the calculated landmarks as .ply files
    :param landmark_coordinates: The numpy array of landmark coordinates
    :param vtp_mesh_file_path: the Path object to the vtp-format mesh
    :param time_now: the datetime of when the whole experiment was begun
    """

    landmark_ply = pv.PolyData(landmark_coordinates)
    landmark_ply_path = vtp_mesh_file_path.parent / ('predicted_landmarks_ply_' + time_now) / (vtp_mesh_file_path.stem +
                                                                                               '_pred_landmarks.ply')
    if not os.path.exists(landmark_ply_path.parent):
        os.makedirs(landmark_ply_path.parent)

    landmark_ply.save(str(landmark_ply_path))


def investigate_landmarks(landmarks, vtp_mesh_file_path, time_now):
    """
    Export images of the landmarks placed on the mesh.
    :param landmarks: the vtk object with the predicted landmarks.
    :param vtp_mesh_file_path: the Path object to the file path of the mesh in .vtp format
    :param time_now: the datetime of when the whole experiment was begun
    """

    landmark_coordinates = get_landmark_coordinates(landmarks)

    export_ply_landmark_coordinates(landmark_coordinates, vtp_mesh_file_path, time_now)


def manually_visualise_landmarks(meshes_to_visualise, vis_control):
    """
    Creates a PyVista Plotter visual of a mesh and its HSA-predicted landmarks.
    :param meshes_to_visualise: a dictionary with mesh subtypes and a list of mesh id numbers to visualise
    """

    ply_synth_data_path = Path('./synth_data/ply')
    ply_landmarks_path = Path('./synth_data/vtp_python_ply_landmarks')

    if not vis_control:
        del meshes_to_visualise['control']

    for subtype in list(meshes_to_visualise.keys()):

        subtype_folder = ply_synth_data_path / subtype
        mesh_id_nums = meshes_to_visualise[subtype]
        landmarks_coordinates_dir = ply_landmarks_path / subtype

        for mesh_id_num in mesh_id_nums:
            zero_padded_id = str(mesh_id_num).zfill(3)
            mesh_file_path = list(subtype_folder.glob(f'*{zero_padded_id}_cp.ply'))[0]
            mesh_predicted_landmarks_path = list(landmarks_coordinates_dir.glob(f'*{zero_padded_id}_cp_pred_landmarks.ply'))[0]

            p = pv.Plotter()
            p.add_mesh(pv.read(str(mesh_file_path)))
            landmark_coordinates = pv.read(str(mesh_predicted_landmarks_path))
            p.add_points(landmark_coordinates, render_points_as_spheres=True, point_size=15, color='r')
            p.add_text('{}'.format(mesh_file_path.name), position='upper_right', color='k')
            p.view_xy()
            p.show()


def load_mesh_files_info(json_file_path):
    """
    Read the list of paths used in a test data set to create a dictionary of subtypes and mesh ids
    :param json_file_path: the Path object to the json file of the test dataset
    :return: a dictionary with subtypes as keys and a list of mesh id numbers as values
    """

    with open(json_file_path, "r") as file:
        json_data = file.read()
    paths_list = json.loads(json_data)

    mesh_id_per_subtype = dict()
    for i, path in enumerate(paths_list):
        pattern = r'\\([^\\]+)\\[^\\]+_(\d+)_'
        match = re.search(pattern, path)
        subtype = match.group(1)
        if subtype not in mesh_id_per_subtype:
            mesh_id_per_subtype[subtype] = []
        mesh_id = int(match.group(2))
        mesh_id_per_subtype[subtype].append(mesh_id)

    return mesh_id_per_subtype


def calculate_hsa_scores(vtp_data_path, hsa_exec_params):
    hsa_indices = dict()

    for subtype_folder in vtp_data_path.iterdir():

        hsa_indices[subtype_folder.name] = dict()

        for mesh_vtp_file_path in subtype_folder.glob('*_cp.vtp'):

            # Load mesh and get its info
            mesh = ReadPolyData(str(mesh_vtp_file_path))
            mesh_subtype, mesh_id_num = get_mesh_info(mesh_vtp_file_path)
            print(f'Working on {mesh_subtype} case #{mesh_id_num}...')

            # Place landmarks on mesh, compute its hsa index, and store
            landmarks, _ = PlaceLandmarks(mesh, crop=hsa_exec_params['crop'], verbose=True,
                                          crop_percentage=hsa_exec_params['crop_percentage'])
            investigate_landmarks(landmarks, mesh_vtp_file_path, hsa_exec_params['time_of_exec'])

            if hsa_exec_params['calculate_hsa']:
                _, hsa_index = ComputeHSAandRiskScore(mesh, landmarks, hsa_exec_params['age'], hsa_exec_params['sex'],
                                                  verbose=False)
                hsa_indices[mesh_subtype][mesh_id_num] = hsa_index

    return hsa_indices


def measure_hsa_of_synth_data():
    vtp_format_synth_data_dir = Path('./synth_data/vtp_python')
    hsa_scores_file_path = Path('hsa_scores.xlsx')
    time_now = datetime.datetime.now().strftime("%B_%d_%H_%M")
    hsa_execution_parameters = {'age': 200,
                                'sex': 'M',
                                'crop': False,
                                'crop_percentage': 0,
                                'calculate_hsa': False,
                                'time_of_exec': time_now}

    if os.path.exists(hsa_scores_file_path):
        hsa_scores = load_hsa_scores(hsa_scores_file_path)
    else:
        hsa_scores = calculate_hsa_scores(vtp_format_synth_data_dir, hsa_execution_parameters)
        export_to_excel(hsa_scores, output_path=hsa_scores_file_path)


def visualise_model_both_landmarks():
    model_both_test_data_path = Path('./synth_data/test_datasets/testdata_model_0108_both.json.json')
    dataset_meshes_ids = load_mesh_files_info(model_both_test_data_path)
    visualise_control = False
    manually_visualise_landmarks(dataset_meshes_ids, visualise_control)


def visualise_model_metopic_landmarks():
    model_both_test_data_path = Path('./synth_data/test_datasets/testdata_model_0108_metopicB.json.json')
    dataset_meshes_ids = load_mesh_files_info(model_both_test_data_path)
    visualise_control = False
    manually_visualise_landmarks(dataset_meshes_ids, visualise_control)


def visualise_model_sagittal_landmarks():
    model_both_test_data_path = Path('./synth_data/test_datasets/testdata_model_0108_sagittalB.json.json')
    dataset_meshes_ids = load_mesh_files_info(model_both_test_data_path)
    visualise_control = False
    manually_visualise_landmarks(dataset_meshes_ids, visualise_control)


if __name__ == '__main__':
    visualise_model_sagittal_landmarks()

